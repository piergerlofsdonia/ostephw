#### Chapter 6 Notes:
##### System Calls, Traps, & CPU Control.

* Within the confines of the process, the CPU is doing what people are taught CPUs do - see: the best lecture on Computer Heuristics by Feynman [7] - read an instruction, increment the program counter, execuite the instruction, repeat ad infinitum - when the process needs to do something outside the confines of the process (access I/O, fork a new process, etc) it needs to ask the kernel using a system call. System calls, along with exceptions (erroneous code) and interrupts (hardware) create a psuedo-window into the kernel (transfer from user mode to kernel mode) using a _trap_. When any of these interrupts occur, the kernel has a specific handler that interprets the request from the process and enacts it dependent on whether it is valid and the kernel is actually permissable to execute the requirement (e.g. illegal actions can cause the kernel to redirect to a handler that simply kills the process - a bug in your code can cause the program to crash due to this).  
* A process running without any time-sharing is called _direct execution_. The OS creates the process (entry in process list/table), allocates memory, loads the program, sets up its stack (including static variables such as argc/argv), clears down any required registers, and executes the main() call (entry point). After the program is run, it also clears down the process, freeing any memory and removing the process. This approach lacks any ability to control the CPU during process execution or allow multiple processes to time-share the CPU. 
* Splitting CPU hardware access into two modes: user (level-3) and kernel (level-0) enables an operating system to retain control of restricted operations such as accessing I/O. In order for a program running in user mode to be able to access I/O in this manner, a system call is used. A system call, in this context, is a software procedure that executes a trap instruction to enter the kernel and execute the restricted operation before returning to the user code via a return-from-trap instruction. 
* _How does a system call actually work?_ When invoked, a lookup of the _trap table_ (on x86 this is just the interrupt descriptor table) gives a %cs value (this is the CPL, current priv. level, this needs to match or exceed the descriptor priviledge level - DPL) and a %eip value at an index within the table (this is the _n_ or _x_ argument given to INT, max 255). [8] The process has its own stack containing a completely different %eip (instruction pointer) and %cs (code segment) value so it needs to be stored. Just as in traditional code segments (e.g. during a function call), the information to restore on returning from the trap handler is pushed to a _trap frame_ this is a seperate, private stack in the kernel that cannot be modified by the user - this avoids malicious content from being injected by the user (e.g. if the %eip register had to be reused from the process frame). When the specific handler is done executing the kernel-level handler code, a return is called (_return-from-trap_, `iret`, etc) which pops the old values off the kernel stack and back into the registers to be used by the process. [9]
* Side-note: System calls such as `open()` are _technically_ functions/procedures just like any other typical C function (e.g. `printf()` is a procedure from the _stdio_ header). Inside the _system call_ procedure, however, there is a trap operation. A _trap_ is like an interrupt, except it is not generated by the hardware. Both interrupts (e.g. disk I/O transfers [1] ) and exceptions (e.g. divide by zero [2] ) allow entry into the unprotected depths of the CPU hardware (ring zero, kernel mode, protection ring), a trap instruction within the C procedure, e.g. `open()`, meticulously sets input and return arguments before and after executing (usually assembly) code to perform the required action. Finally, the trap instruction works synchronously, saving the state of the user code and data segments to be restored after the trap is complete, this information is pushed onto and popped off a _kernel stack_ which is allocated on a per-process basis.
* Side-note additional: Software interrupts are traditionally (on UNIX) implemented exclusively using 0x80 with an integer value stored in the EAX register determining the kernel function to reference [3] -(see: [4] for more). This is not the case on DOS systems, where software interrupts (through the use of `INT`) can be used to access various operations within the interrupt vector table, for example: `INT 0x21` is used in DOS systems to access I/O operations.
* In order to correctly route from kernel access (_via the trap instruction_) to the correct instruction to execute (e.g. an I/O operation), a machine will set up a _trap table_ at boot time (systems will always boot into the BIOS in real mode before putting the CPU into protected mode for user operations - this is mainly down to how x86 PC hardware evolved [5]). When a system call occurs, an ID (system call number) is checked as a form of protection (checked within the _trap handler_ code). Another form of protection is implemented by disallowing the user from executing the instruction used to find the location of the trap table.

##### Process switching.

* Software is reliant upon a transfer of control: A running process needs to pass control to the kernel to make system calls, as discussed, as well passing control to the operating system for it to manage processes effectively. Processes also relinquish control (giving it back to the OS) when an exception occurs, such as a divide-by-zero - a trap will allow the OS to regain control of the CPU and will (in this case) kill the process. 
* A yield system call (e.g. `sched_yield()` from `sched.h`) does nothing except relinquish control from the process, giving it back to the operating system.
* Operating systems can take a passive (cooperative) or active (non-cooperative) approach, either waiting for a system call or exception (leading to trap handler call) to occur in order to regain control of the CPU and take action based on the state of the process, or, alternatively, use a timed interrupt which will allow the OS to regain control of the CPU every few milliseconds (dependent on the clock cycle of the timer chip) causing a context switch (save of state to restore on return).
* The benefit of the timer interrupt is the predictability of the transfer of control from process to OS, if a process is left to its own devices and causes an infinite loop with no execeptions or system calls, there is no way for the operating system to kill that process.
* A context switch allows processes to be saved momentarily, meaning the OS can switch to another process, restoring it to a running state and still have the previous, now stalled, process _saved_ (well... the minumum data required to restore it anyway: general-purpose register values, the program counter [PC], and kernel stack pointer) on the kernel stack to be restored once the current process is finished or switched, this stored data is referred to as the PCB (annoyingly) or the _process control block_ (alternatively, the _process switch-frame_) [6]. 
* Context switching is a very fast process, taking less than a microsecond in modern operating systems, on modern hardware. 
* Concurrent system calls & traps are possible due to modern operating systems implementing locking schemes (low-level mutexes) that stop internal structures from being altered by multiple system calls, or by temporarily halting interrupts whilst a high-importance interrupt handler is executing.
* Limited direct execution is a method of _baby-proofing_ the CPU so that a process may not do anything idiotic with it - if it does, the operating system can step in and handle bad requests (system calls).  
#### Homework notes:
* gettimeofday() is borderline useless for measuring the speed of system calls.
* clock_gettime can be used to measure time periods of nanoseconds, which is perfect for this. There's also the option of using rdtsc (and rdtscp for a seralised version) - see rdtsc.h for more information surrounding that.
* The general gist is that rdtsc can be useful but requires a lot of CPU information to use correctly (e.g. maximum clock frequency to convert rdtsc units to seconds), it also requires serialisation to correctly clock as the CPU may change the order of instructions so that the timer does not actually take a sample at the correct (or perceived) period in time.
* When timing a context switch, some OS-level functionality is required. Two pipes (parent I/O and child I/O) can be used to connect the parent and child process. `Read()` and `Write()` used within the process (which reads/writes to the correct pipe fd) will cause the current process to be blocked whilst awaiting communication - this is the technique used in `timecontextswitch`. The code example provided will accurately time context switches to ~2.2-2.5us (this figure is also noted by [Eli Bendersky](https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/)) over ~250k cycles, reducing the number of cycles increases this average time signficantly (e.g. run the program at ~50 cycles and the output will be ~4.5us).

#### Sources:

[1] Interrupt Driven I/O: http://inputoutput5822.weebly.com/interrupt-driven-io.html

[2] x86, What's the difference between a trap and an interrupt: https://stackoverflow.com/questions/3149175/what-is-the-difference-between-trap-and-interrupt

[3] INT (x86 Instruction) Wikipedia: https://en.wikipedia.org/wiki/INT_(x86_instruction)

[4] Linux System Calls: https://www.linuxjournal.com/article/4048

[5] Operating System Design / Interrupts: https://en.wikibooks.org/wiki/Operating_System_Design/Processes/Interrupt

[6] Context Frame Wikipedia: https://en.wikipedia.org/wiki/Context_switch

[7] Richard Feynman on Computer Heuristics: https://www.youtube.com/watch?v=EKWGGDXe5MA

[8] Traps: http://pages.cs.wisc.edu/~gerald/cs537/Summer17/handouts/traps.pdf

[9] Traps, Handlers: http://www.cse.iitd.ernet.in/~sbansal/os/lec/l8.html
